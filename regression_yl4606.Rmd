---
title: "Statistical Analysis"
output: 
  html_document:
    toc: true
    toc_float: true
---
# Hypothesis
In this analysis, we are interested in whether wine is more expensive as its points(rated by *[Wine Enthusiast](https://www.winemag.com/ratings/?utm_source=wineenthusiast.com&utm_medium=affiliate&utm_content=topnav)) increases, adjusting for variables including variety and continent of production.

```{r setup, include = FALSE, echo = FALSE}
library(tidyverse)
library(purrr)
library(broom)
library(modelr)

knitr::opts_chunk$set(
  fig.width = 6, 
  fig.asp = .6,
  out.width = "90%"
)
theme_set(theme_minimal() + theme(legend.position = "bottom"))
options(
  ggplot2.continuous.colour = "viridis",
  ggplot2.continuous.fill = "viridis"
)
scale_colour_discrete = scale_colour_viridis_d
scale_fill_discrete = scale_fill_viridis_d
```

```{r, warning = FALSE, echo=FALSE}
# reading two datasets
wine_150k = read_csv("./data/winemag-data_first150k.csv")
conti_country = read_csv("./data/country-and-continent-codes-list-csv_csv.csv")
```

a little bit tidying, add continent column to 150k wine data
```{r, warning = FALSE, echo=FALSE}
# wine data tidy
wine_150k = wine_150k %>% 
  janitor::clean_names() %>% 
  select(country, points, price, variety) %>% 
  mutate(country = factor(country),
         variety = factor(variety)) %>% 
  drop_na(country)

#conti_country data tidy
conti_country_tidy <- conti_country %>% 
  janitor::clean_names() %>% 
  separate(country_name, into = c("country", "prefix"), sep = ",") %>% 
  mutate(
    country = replace(country, country == "Slovakia (Slovak Republic)", "Slovakia"),
    country = replace(country, country == "United Kingdom of Great Britain & Northern Ireland", "England"),
    country = replace(country, country == "Korea", "South Korea"),
    country = replace(country, country == "United States of America", "US"),
  ) %>% ## standardize country names to do left_join
  select(continent_name, country) %>% 
  mutate(continent = as.factor(continent_name)) %>% 
  select(-continent_name)

rm(conti_country)

#left_join to wine data to get continent info, US-France row removed
wine_with_conti<-
  left_join(wine_150k, conti_country_tidy, by = ("country" = "country")) %>% 
  mutate(continent = fct_relevel(continent, "North America")) %>%  ##let US as the reference
  select(country, continent, everything()) %>% 
  drop_na(continent) 
```

# Distribution of Price(Y)
```{r, echo=FALSE}
wine_with_conti %>% 
  ggplot(x = price) +
  stat_density(aes(x= price), geom="line")
```
The highly skewed pattern needs to be log-linear transformed before fitting the regression model.

# Scatter plot: log_Price(Y) vs Points(X) by Variety(Z)
```{r, echo=FALSE}
# 632 unique varieties, select most frequent 4 vareties to fit the model
top_variety <- wine_with_conti %>% 
  group_by(variety) %>% 
  summarise(count = n()) %>% 
  arrange(desc(count)) %>% 
  filter(count>10000)

top_variety_list <- as.vector(top_variety$variety)

# wine_with_conti filtered
top_wine_with_conti<- 
  wine_with_conti %>% 
  filter(variety %in% top_variety_list) %>% 
  mutate(
    variety = fct_infreq(variety),
    log_price = log(price)
  ) ## most frequent variety as the reference

# scatter plot
top_wine_with_conti %>% 
  ggplot(aes(x = points, y = log_price, color = variety)) +
  geom_point(alpha = 0.5)+
  geom_smooth(method='lm')
```

Comment: We see a linear trend in price vs. points. This implies a positive correlation between price and points. The trend lines for the 4 most frequent varieties are very close together. So there is a similar positive correlation between price and points for each variety. 

# Significance of interaction points*variety

```{r, warning = FALSE, echo=FALSE}
lm_p_v_pv <- lm(log_price ~ points + variety, data = top_wine_with_conti)

summary(lm_p_v_pv)$r.squared
```

```{r, warning = FALSE, echo = FALSE}
lm_p_v_pv <- lm(log_price ~ points*variety, data = top_wine_with_conti)

summary(lm_p_v_pv)$r.squared
```

Comment: r^2 of 0.429 without interaction term suggests a moderate association between points, variety and log(price). Although there is a significant p-value of points - variety interactions, the coefficient of determination does not change much when interaction term is added.  Therefore, we consider the interaction as not significant, which means that the relationship between points and price does not vary by different variety. So we delete the term points*variety from model. 

# log_Price(Y) vs. Points(X) + Variety(Z) + Continent(M) 

Is continent significant?

```{r, warning = FALSE, echo=FALSE}
# test significance of categorical predictor 'variety'
fit_null = lm(log_price ~ points + variety, data = top_wine_with_conti)
fit_alt = lm(log_price ~ points + variety + continent, data = top_wine_with_conti)

anova(fit_null, fit_alt) %>% 
  broom::tidy()  #p-val = 0
```

Yes. Since p-val = 0, the larger model (log_price ~ points + variety + continent) is superior, which means continent is a significant variable.

# For easier interpretation: stratified analysis by continent
```{r, warning = FALSE, echo=FALSE}
# nested within continent
nest_lm_res =
  top_wine_with_conti %>% 
  nest(data = -continent) %>% 
  mutate(
    models = map(data, ~lm(log_price ~ points + variety, data = .x)),
    results = map(models, broom::tidy)) %>% 
  select(-data, -models) %>% 
  unnest(results)
```

```{r, warning = FALSE, echo=FALSE}
# price ~ points + variety for stratified continent
nest_lm_res %>% 
  select(continent, term, estimate) %>% 
  mutate(term = fct_inorder(term)) %>% 
  pivot_wider(
    names_from = term, values_from = estimate) %>% 
  knitr::kable(digits = 3)
```

# Take a closer look at North America
```{r, warning = FALSE, echo=FALSE}
# check residual assumption for continent North America
north_america_df <- top_wine_with_conti %>% 
  filter(continent == 'North America')

fit_na = lm(log_price ~ points + variety, data = north_america_df)

modelr::add_residuals(north_america_df, fit_na) %>% 
  ggplot(aes(x = points, y = resid)) +
  geom_point() +
  theme_bw()
```
Unequal variance of residual tells us that we need to do bootstrap before fitting the model.

# bootstrap 1000 times

```{r, warning = FALSE, echo=FALSE, cache = TRUE}
north_america_df %>% 
  modelr::bootstrap(1000, id = "strap_number") %>% 
  mutate(
    models = map(.x = strap, ~lm(log_price ~ points + variety, data = .x)),
    results = map(models, tidy)) %>% 
  select(strap_number, results) %>% 
  unnest(results) %>%
  group_by(term) %>% 
  summarize(
    mean_est = mean(estimate),
    sd_est = sd(estimate)
  ) 
```


